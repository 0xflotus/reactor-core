[[getting-started]]
== *Introducing Reactor Core*

[quote, Preface, TL;DR]
Reactor is a foundational library for building demanding, realtime *Data-Streaming* applications and micro, nano, or pico-services that must exhibit *Low-Latency* and be *Fault-Tolerant*.

[[start]]
=== What is Reactor ?

In a nutshell Reactor is a lightweight, foundational library for the JVM that helps your service or application to _efficiently_ and _asynchronously_ pass messages.

.What do you mean by "efficiently"?
****
* Little to no *memory* garbage created just to pass a message from A to B.
* Handle *overflow* when consumers are slower at processing messages than the producer is at producing them.
* Provide for *asynchronous flow*--without blocking--if at all possible.
****

From empirical studies (mostly _#rage_ and _#drunk_ tweets), we know that asynchronous programming is hard--especially when a platform like the JVM offers so many options. Reactor aims to be truly non-blocking for a majority of use cases and we offer an API that is measurably more efficient than relying on low-level primitives from the JDK's _java.util.concurrent_ library. Reactor provides alternatives to (and discourages the use of):

* Blocking wait : e.g. Future._get()_
* Unsafe data access : e.g. ReentrantLock._lock()_
* Exception Bubbles : e.g. try...catch...finally
* Synchronization blocks : e.g. synchronized{ }
* Wrapper Allocation (GC Pressure) : e.g. new Wrapper<T>(event)

Being non-blocking matters--especially when scaling message-passing becomes critical (10k msg/s, 100k msg/s 1M...). There is some theory behind this (see http://en.wikipedia.org/wiki/Amdahl%27s_law[Amdahl's Law]), but we get bored and distracted easily, so let's first appeal to common sense.

Let's say you use a pure https://docs.oracle.com/javase/tutorial/essential/concurrency/executors.html[Executor] approach:

[source,java]
----
private ExecutorService  threadPool = Executors.newFixedThreadPool(8);

final List<T> batches = new ArrayList<T>();

Callable<T> t = new Callable<T>() { // <1>

    public T run() {
        synchronized(batches) { // <2>
            T result = callDatabase(msg); // <3>
            batches.add(result);
            return result;
        }
    }
};

Future<T> f = threadPool.submit(t); // <4>
T result = f.get() // <5>
----
1> Allocate Callable--might lead to GC pressure.
2> Synchronization will force stop-and-check for every thread.
3> Potentially consumes slower than producer produces.
4> Use a ThreadPool to pass the task to the target thread--definitely produces GC pressure via FutureTask.
5> Block until callDatabase() replies.

In this simple example, it's easy to point out why scale-up is very limited:

* Allocating objects might cause *GC pauses*, especially if the tasks stick around too long.
** Every GC Pause will degrade performance globally.
* A Queue is *unbounded* by default. Because of the database call, tasks will pile up.
** A backlog is not really a Memory Leak but the side effects are just as nasty: more objects to scan during GC pauses; risk of losing important bits of data; etc...
** Classic Linked Queues generate memory pressure by allocating Nodes. Lots of them.
* A vicious cycle kicks-in when *blocking replies* are used.
** Blocking replies will cause producer slow-down. In practice, the flow becomes basically *synchronous* since we have to wait for each reply before submitting more tasks.
** Any Exception thrown during the conversation with the datastore will be passed in an uncontrolled fashion to the producer, negating any fault-tolerance normally available by segregating work around a Thread boundary.

Being fully and truly non-blocking is hard to achieve--especially in a world of distributed systems which have fashionable monikers like *Micro-Service Architectures*. Reactor, however, makes few compromises and tries to leverage the best patterns available so the developer doesn't have to feel like they're writing a mathematical thesis rather than an asynchronous nanoservice.

Nothing travels faster than light (besides gossip and viral cat videos) and latency is a real-world concern every system has to deal with at some point. To that end:

.Reactor offers a framework that helps you mitigate nasty latency-induced side-effects in your application and do it with minimal overhead by:
****
* Leveraging some smart structures, we traded-off the *allocation issue* at runtime with pre-allocation at startup-time;
* Main message-passing structures come *bounded* so we don't pile up tasks infinitely;
* Using popular patterns such as *Reactive and Event-Driven Architectures*, we offer *non-blocking end-to-end flows* including replies;
* Implementing the new <<gettingstarted.adoc#reactivestreams,Reactive Streams>> Standard, to make bounded structures *efficient* by not requesting more than their current capacity;
* Applied these concepts to <<net.adoc#net-overview,IPC>> and provide *non-blocking IO drivers* that understand flow-control;
* Expose a Functional API to help developers organize their code in a *side-effect free* way, which helps you determine where you are thread-safe and fault-tolerant.
****

=== About the Project

The project started in 2012, with a long internal incubation time. Reactor 1.x appeared in 2013. Reactor 1 has been deployed successfully by various organizations, both Open Source (e.g. Meltdown) and Commercial (e.g. Pivotal RTI). In 2014 we started collaborating on the emerging <<gettingstarted.adoc/#reactivestreams,Reactive Streams Standard>> and started a massive re-engineering targeting April 2015 for version 2.0. The Reactive Streams Standard closed the last gap in our _Dispatching_ mechanism: controlling how much in-flight data was hitting Thread boundaries.

Parallel to that work we also decided to re-align some of our Event-Driven and Task Coordination API to the increasingly popular and documented <<gettingstarted.adoc/#rx,Reactive Extensions>>.

Reactor Core is sponsored by http://pivotal.io[Pivotal]

Reactor Core is http://www.apache.org/licenses/LICENSE-2.0.html[Apache 2.0 licensed] and available on https://github.com/reactor/reactor[GitHub].

=== Requirements

* Reactor needs at minimum Java 7 to execute.
** But the full expressive potential of functional composition happens with Java 8 Lambdas.
** As a fallback have a look at Spring, Clojure or Groovy extensions.
* Reactor runs at full capacity when the JVM supports *Unsafe* access
* Reactor is packaged as traditional JAR archives in Maven Central and can be pulled into any JVM project as a dependency using your preferred build tool.

[[reactivestreams]]
=== Reactive Streams

http://www.reactive-streams.org[Reactive Streams] is a reactive standard, adopted by different vendors and tech
industrials including Netflix, Oracle, Pivotal or Typesafe with a target to include the specification into Java 9 and onwards.

.The Reactive Streams Contract
image::images/rs.png[The Reactive Streams Contract, width=500, align="center"]

.The Reactive Streams Interfaces
****
* https://github.com/reactive-streams/reactive-streams-jvm/blob/master/api/src/main/java/org/reactivestreams/Publisher.java[org.reactivestreams.Pubslisher]: A source of data (from 0 to N signals where N can be unlimited). It optionally provides for 2 terminal events: error and completion.
* https://github.com/reactive-streams/reactive-streams-jvm/blob/master/api/src/main/java/org/reactivestreams/Subscriber.java[org.reactivestreams.Subscriber]: A consumer of a data sequence (from 0 to N signals where N can be unlimited). It receives a subscription on initialization to _request_ how many data it wants to process next. The other callbacks interact with the data sequence signals: next (new message) and the optional completion/error.
* https://github.com/reactive-streams/reactive-streams-jvm/blob/master/api/src/main/java/org/reactivestreams/Subscription.java[org.reactivestreams.Subscription]: A small tracker passed on initialization to the Subscriber. It controls how many data we are ready to consume and when do we want to stop consuming (cancel).
* https://github.com/reactive-streams/reactive-streams-jvm/blob/master/api/src/main/java/org/reactivestreams/Processor.java[org.reactivestreams.Processor]: A marker for components that are both Subscriber and Publisher!
****

.The Reactive Streams publishing protocol
image::images/signals.png[The Publishing Sequence, width=400, align="center"]

.There are two ways to request data to a Publisher from a Subscriber, through the passed Subscription:
****
* *Unbounded*: On Subscribe, just call _Subscription#request(Long.MAX_VALUE)_.
* *Bounded*: On Subscribe, keep a reference to Subscription and hit its _request(long)_ method when the Subscriber is ready to process data.
** Typically, Subscribers will request an initial set of data, or even 1 data on Subscribe
** Then after onNext has been deemed successful (e.g. after Commit, Flush etc...), request more data
** It is encouraged to use a linear number of requests. Try avoiding overlapping requests, e.g. requesting 10 more data every next signal.
****
